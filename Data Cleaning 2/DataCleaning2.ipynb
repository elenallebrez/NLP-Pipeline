{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db84e2ad-e480-42f3-96b2-01643004741d",
   "metadata": {},
   "source": [
    "# JSON Post-Processing for Clean Conversations\n",
    "\n",
    "This notebook performs a second cleaning step on the JSON files generated earlier.  \n",
    "The goal is to:\n",
    "1. Detect redundant or irrelevant chatbot messages.  \n",
    "2. Remove them while keeping the meaningful conversation intact.  \n",
    "3. Save the cleaned JSON files in a new folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918fa4f-0d76-4538-b5bf-ec048f6f88d0",
   "metadata": {},
   "source": [
    "### 1. Import required libraries\n",
    "We use `os` and `json` for file handling, and `AzureOpenAI` for making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c06a8a-9a67-4480-b398-09b4bd262ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ab302-1760-4e53-ad6e-3bda6bc08039",
   "metadata": {},
   "source": [
    "### 2. Define input and output directories\n",
    "We read the raw JSON files from `./Json Files` and store the cleaned versions in `cleanprocessed_json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014a1753-d106-43db-8fca-2a356126dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = r\"./Json Files\"\n",
    "output_dir = os.path.join(folderpath, \"cleanprocessed_json\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77060e8-03bb-4964-81b4-d77fd68aa8c1",
   "metadata": {},
   "source": [
    "### 3. Initialize Azure OpenAI client\n",
    "We configure the client with API key, version, and endpoint to access the model for message filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795ed87d-a8cc-46ca-99bf-923e3c9ba2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=\"YOUR-API-KEY\",\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://fallbackmodel.openai.azure.com/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f2c07-759b-470b-9411-8a9bc2d746fc",
   "metadata": {},
   "source": [
    "### 4. Define message filter\n",
    "The function `clean_and_deidentify_text` analyzes a **bot message** and decides whether it is redundant or irrelevant to the mental health context.  \n",
    "It returns `True` if the message should be removed, and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1e25b7-de93-411b-9374-d3d48c059f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_deidentify_text(text):\n",
    "    prompt = f\"\"\"\n",
    "        You are a strict content filter for a mental health chatbot.\n",
    "    Your task is to analyze a single chatbot message and decide if it is REDUNDANT or IRRELEVANT to a conversation focused on the user's emotional well-being.\n",
    "\n",
    "    Return ONLY:\n",
    "    - \"true\" → if the message:\n",
    "        - Is a **generic greeting** (e.g., \"Hello\", \"Hi\", \"Hey\", \"Hey there!\", \"Hi there!\", \"Good to see you\", \"Hope you're doing well\", \"How are you today?\", \"Nice to see you again\", \"Welcome back\", \"How can I help?\", etc.).\n",
    "        - Contains any **opening pleasantries**, even if part of a longer sentence (e.g. I am Healo, your personal AI therapist and companion for emotional health. (:sparkles) Just saying this is a safe and confidential space for you to share anything. Remember I am always here for you. You've got this! (:sparkles),So tell me how's it going? Anything on your mind lately?,So, how have you been? Anything interesting on your mind these days?, \"Hey! How are you doing today? I’m here to help\").\n",
    "        - Refers to **reminders**, **rendering GIFs**, **Pomodoro timers**, **tests**, **interlink cards**, **personality reports**, **traffic alerts**, or **any automated functionality unrelated to emotional well-being**.\n",
    "        - Mentions or refers to **images**, **generic external links**, or **non-emotional function cards**.\n",
    "        - Is **automatically generated** or a **repetitive template message** that doesn’t offer emotional insight.\n",
    "        - Contains meta-chat like: \"Before we proceed, could you please share what you have in mind or what you'd like to do?\"\n",
    "\n",
    "    - \"false\" → if the message provides emotional support, asks about the user's feelings, encourages self-reflection, offers coping tools or genuine mental health insight.\n",
    "\n",
    "    Only analyze **bot messages**. Never return true for user messages.\n",
    "\n",
    "    Only return **true** or **false** — no explanations.\n",
    "\n",
    "    Original Text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-fallback\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for data cleaning.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        return answer == \"true\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error llamando a la API: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137e282-1443-4ae1-bed1-ee8b59821bb7",
   "metadata": {},
   "source": [
    "### 5. Clean a single JSON file\n",
    "The function `clean_json_file`:\n",
    "1. Loads the JSON file.  \n",
    "2. Iterates over its messages.  \n",
    "3. Removes bot messages marked as redundant.  \n",
    "4. Returns the cleaned conversation object.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27da3b83-e8ec-4488-8f9b-cc1003df4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    cleaned_messages = []\n",
    "\n",
    "    for message in data.get(\"messages\", []):\n",
    "        if message[\"role\"] == \"bot\":\n",
    "            if clean_and_deidentify_text(message[\"content\"]):\n",
    "                continue\n",
    "            else:\n",
    "                cleaned_messages.append(message)\n",
    "        else:\n",
    "            cleaned_messages.append(message)\n",
    "\n",
    "    cleaned_data = {\n",
    "        \"conversation_id\": data.get(\"conversation_id\"),\n",
    "        \"messages\": cleaned_messages,\n",
    "        \"language\": data.get(\"language\"),\n",
    "        \"country\": data.get(\"country\"),\n",
    "        \"timestamp\": data.get(\"timestamp\"),\n",
    "        \"insight_score\": data.get(\"insight_score\"),\n",
    "        \"isPaid\": data.get(\"isPaid\")\n",
    "    }\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb67d5e-5b9d-4c2b-988d-9835b6053755",
   "metadata": {},
   "source": [
    "### 6. Clean all JSON files in a folder\n",
    "The function `clean_all_jsons`:\n",
    "- Loops through all JSON files in the input folder.  \n",
    "- Calls `clean_json_file` for each one.  \n",
    "- Saves the cleaned version into the output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd52156-64d4-4a09-93fe-c8c1e6532ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_jsons(folderpath, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    json_files = [f for f in os.listdir(folderpath) if f.endswith(\".json\")]\n",
    "    json_files.sort()\n",
    "\n",
    "    for idx, filename in enumerate(json_files):\n",
    "        input_path = os.path.join(folderpath, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        print(f\"Processing {filename} ({idx}...\")\n",
    "        cleaned = clean_json_file(input_path)\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "            json.dump(cleaned, f_out, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd4933-a447-446b-89c7-8432a1591ce0",
   "metadata": {},
   "source": [
    "### 7. Run the pipeline\n",
    "We now run the cleaning process for all JSON files in the input folder.  \n",
    "The cleaned files will be saved in `cleanprocessed_json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5346e07-0ba0-4317-bf51-35a79fe04e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing conversation1.json (0...\n",
      "Processing conversation10.json (1...\n",
      "Processing conversation2.json (2...\n",
      "Processing conversation3.json (3...\n",
      "Processing conversation4.json (4...\n",
      "Processing conversation5.json (5...\n",
      "Processing conversation6.json (6...\n",
      "Processing conversation7.json (7...\n",
      "Processing conversation8.json (8...\n",
      "Processing conversation9.json (9...\n"
     ]
    }
   ],
   "source": [
    "clean_all_jsons(folderpath, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
