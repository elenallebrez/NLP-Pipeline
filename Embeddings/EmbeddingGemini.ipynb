{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Embeddings with Gemini\n",
    "\n",
    "This notebook generates embeddings for chatbot conversations.  \n",
    "Steps:\n",
    "1. Load JSON files containing cleaned conversations.  \n",
    "2. Extract message text.  \n",
    "3. Use OpenAI's embedding model to create vector representations.  \n",
    "4. Save the embeddings to new JSON files for later use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required libraries\n",
    "We use:\n",
    "- `genai` for embeddings.  \n",
    "- `os` and `json` for file handling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1753702677488
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configure API key and paths\n",
    "We define:\n",
    "- The folder with the input JSON files (`processed_json`).  \n",
    "- The folder where embeddings will be saved (`embeddingopenAIFiles`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1753702679252
    }
   },
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"YOUR-API-KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1753703083588
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"../raw data/processed_json\"\n",
    "out_path = \"embeddingGeminiFiles\"\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define embedding model\n",
    "We use `embedding-001` with 768 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1753702682987
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"models/embedding-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Function to generate an embedding\n",
    "This function calls OpenAI‚Äôs embedding API with the selected model and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_embedding(texto):\n",
    "    try:\n",
    "        response = genai.embed_content(\n",
    "            model=EMBEDDING_MODEL,\n",
    "            content=texto,\n",
    "            task_type=\"semantic_similarity\",  # puedes cambiarlo seg√∫n necesidad\n",
    "        )\n",
    "        return response['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error con Gemini embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. List input files\n",
    "We check which JSON files exist in the input folder.\n",
    "For testing, we only take the first 10 files.5. List input files\n",
    "\n",
    "### 6. Process each file\n",
    "For every JSON file:\n",
    "1. Open and parse the content.  \n",
    "2. Extract message texts.  \n",
    "3. Generate embeddings for each text.  \n",
    "4. Save the embeddings into a new JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1753703007082
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Carpeta de entrada: /mnt/batch/tasks/shared/LS_root/mounts/clusters/elena1/code/Users/elena/elena/raw data/processed_json\n",
      "üìÑ Archivos detectados: ['.amlignore', '.amlignore.amltmp', '10ER3iMDW5w4lIlSnHBrIq-in.json', '10er3imdw5w4lilsnhbriq-in.json.amltmp', '111jaycyxHF58KEVIsa0kA-in.json', '11fDRFTlZAPCMeBqTSeYmg-in.json', '12EdU3GcQf2AgjlcgTLb4R-in.json', '12UHWJ1DhbmBIcfVJlbSPK-in.json', '13KMJrTS9SO2aIA8r7SNCj-in.json', '147nMJUjrHyIxKu9Aoka4U-in.json']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'embeddingGeminiFiles/10ER3iMDW5w4lIlSnHBrIq-in_embeddings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m nombre_salida \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(name_file)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_embeddings.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m ruta_salida \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_path, nombre_salida)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mruta_salida\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     67\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(embeddings, f)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Procesado y guardado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruta_salida\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(embeddings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vectores)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embeddingGeminiFiles/10ER3iMDW5w4lIlSnHBrIq-in_embeddings.json'"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ Carpeta de entrada:\", os.path.abspath(folder_path))\n",
    "\n",
    "try:\n",
    "    files = sorted(os.listdir(folder_path))[:10]\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå La carpeta {folder_path} no existe.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üìÑ Archivos detectados:\", files)\n",
    "\n",
    "# ‚úÖ Procesar archivos\n",
    "for name_file in files:\n",
    "    ruta = os.path.join(folder_path, name_file)\n",
    "\n",
    "    if not name_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    if not os.path.isfile(ruta):\n",
    "        print(f\"‚ö†Ô∏è Archivo no encontrado (saltado): {ruta}\")\n",
    "        continue\n",
    "\n",
    "    with open(ruta, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error leyendo {name_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    textos = []\n",
    "\n",
    "    # ‚úÖ Extraer los textos de los mensajes\n",
    "    if isinstance(data, dict) and 'messages' in data:\n",
    "        textos = [msg['content'] for msg in data['messages']\n",
    "                  if isinstance(msg, dict) and 'content' in msg and isinstance(msg['content'], str)]\n",
    "\n",
    "    if not textos:\n",
    "        print(f\"‚ö†Ô∏è No se encontraron textos en {name_file}\")\n",
    "        continue\n",
    "\n",
    "    embeddings = []\n",
    "    for t in textos:\n",
    "        emb = generar_embedding(t)\n",
    "        if emb:\n",
    "            embeddings.append(emb)\n",
    "\n",
    "    if not embeddings:\n",
    "        print(f\"‚ö†Ô∏è No se generaron embeddings en {name_file}\")\n",
    "        continue\n",
    "\n",
    "    nombre_salida = os.path.splitext(name_file)[0] + \"_embeddings.json\"\n",
    "    ruta_salida = os.path.join(out_path, nombre_salida)\n",
    "\n",
    "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "    print(f\"‚úÖ Procesado y guardado: {ruta_salida} ({len(embeddings)} vectores)\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "es"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
