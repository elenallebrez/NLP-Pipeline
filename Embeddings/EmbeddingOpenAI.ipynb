{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Embeddings with OpenAI\n",
    "\n",
    "This notebook generates embeddings for chatbot conversations.  \n",
    "Steps:\n",
    "1. Load JSON files containing cleaned conversations.  \n",
    "2. Extract message text.  \n",
    "3. Use OpenAI's embedding model to create vector representations.  \n",
    "4. Save the embeddings to new JSON files for later use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required libraries\n",
    "We use:\n",
    "- `openai` for embeddings.  \n",
    "- `pandas` and `numpy` (optional, may be useful later).  \n",
    "- `os` and `json` for file handling.  \n",
    "- `cosine_similarity` from sklearn to compare embeddings if needed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1753702644772
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configure API key and paths\n",
    "We define:\n",
    "- The folder with the input JSON files (`processed_json`).  \n",
    "- The folder where embeddings will be saved (`embeddingopenAIFiles`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1753702650934
    }
   },
   "outputs": [],
   "source": [
    "openai.api_key = 'YOUR-API-KEY'\n",
    "folder_path = \"../raw data/processed_json\"\n",
    "out_path = \"embeddingopenAIFiles\"\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define embedding model\n",
    "We use `text-embedding-3-small` with 768 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "EMBEDDING_DIMENSIONS = 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Function to generate an embedding\n",
    "This function calls OpenAI‚Äôs embedding API with the selected model and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_embedding(texto):\n",
    "    response = openai.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=texto,\n",
    "        dimensions=EMBEDDING_DIMENSIONS\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. List input files\n",
    "We check which JSON files exist in the input folder.\n",
    "For testing, we only take the first 10 files.5. List input files\n",
    "\n",
    "### 6. Process each file\n",
    "For every JSON file:\n",
    "1. Open and parse the content.  \n",
    "2. Extract message texts.  \n",
    "3. Generate embeddings for each text.  \n",
    "4. Save the embeddings into a new JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1753703308554
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Carpeta de entrada: /mnt/batch/tasks/shared/LS_root/mounts/clusters/elena1/code/Users/elena/elena/raw data/processed_json\n",
      "üìÑ Archivos detectados: ['.amlignore', '.amlignore.amltmp', '10ER3iMDW5w4lIlSnHBrIq-in.json', '10er3imdw5w4lilsnhbriq-in.json.amltmp', '111jaycyxHF58KEVIsa0kA-in.json', '11fDRFTlZAPCMeBqTSeYmg-in.json', '12EdU3GcQf2AgjlcgTLb4R-in.json', '12UHWJ1DhbmBIcfVJlbSPK-in.json', '13KMJrTS9SO2aIA8r7SNCj-in.json', '147nMJUjrHyIxKu9Aoka4U-in.json']\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/10ER3iMDW5w4lIlSnHBrIq-in_embeddings.json (41 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/111jaycyxHF58KEVIsa0kA-in_embeddings.json (26 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/11fDRFTlZAPCMeBqTSeYmg-in_embeddings.json (55 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/12EdU3GcQf2AgjlcgTLb4R-in_embeddings.json (18 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/12UHWJ1DhbmBIcfVJlbSPK-in_embeddings.json (12 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/13KMJrTS9SO2aIA8r7SNCj-in_embeddings.json (49 vectores)\n",
      "‚úÖ Procesado y guardado: embeddingopenAIFiles/147nMJUjrHyIxKu9Aoka4U-in_embeddings.json (27 vectores)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ Carpeta de entrada:\", os.path.abspath(folder_path))\n",
    "\n",
    "try:\n",
    "    files = sorted(os.listdir(folder_path))[:10]\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå La carpeta {folder_path} no existe.\")\n",
    "    exit()\n",
    "\n",
    "print(\"üìÑ Archivos detectados:\", files)\n",
    "\n",
    "for name_file in files:\n",
    "    ruta = os.path.join(folder_path, name_file)\n",
    "\n",
    "    if not name_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    if not os.path.isfile(ruta):\n",
    "        print(f\"‚ö†Ô∏è Archivo no encontrado (saltado): {ruta}\")\n",
    "        continue\n",
    "\n",
    "    with open(ruta, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error leyendo {name_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    textos = []\n",
    "\n",
    "    # ‚úÖ Extraer los textos de los mensajes\n",
    "    if isinstance(data, dict) and 'messages' in data:\n",
    "        textos = [msg['content'] for msg in data['messages']\n",
    "                  if isinstance(msg, dict) and 'content' in msg and isinstance(msg['content'], str)]\n",
    "\n",
    "    if not textos:\n",
    "        print(f\"‚ö†Ô∏è No se encontraron textos en {name_file}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        embeddings = [generar_embedding(t) for t in textos]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generando embeddings en {name_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    nombre_salida = os.path.splitext(name_file)[0] + \"_embeddings.json\"\n",
    "    ruta_salida = os.path.join(out_path, nombre_salida)\n",
    "\n",
    "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "    print(f\"‚úÖ Procesado y guardado: {ruta_salida} ({len(embeddings)} vectores)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "es"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
