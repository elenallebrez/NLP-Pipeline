{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aff3e85-2eef-4eac-aaa6-4eb6786cf363",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Generator for Mental Health Chatbot Red Flags  \n",
    "This script generates a dataset of synthetic user messages simulating conversations with a mental health chatbot.  \n",
    "The messages are labeled as **ALLOW** (safe, no intervention needed) or **BLOCK** (red flag, requires moderation).  \n",
    "The script uses OpenAI's API to produce realistic, multilingual, and emotionally diverse text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd03488-6ec4-447b-b004-8c383ffd02a6",
   "metadata": {},
   "source": [
    "### 1. Import libraries and initialize OpenAI client  \n",
    "We import the required Python libraries for file handling, dataset creation, and OpenAI API usage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed72455-bbb9-4df7-941d-3728c42dab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='YOUR-API-KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783a16f-2457-461c-b56e-15156817141a",
   "metadata": {},
   "source": [
    "### 2. Configure dataset folders  \n",
    "We define the folder where the generated dataset will be saved.  \n",
    "If the folder doesn‚Äôt exist, it will be created automatically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302320c5-db43-4429-8730-936ab651db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./DataGenerated\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a283a-73da-4c46-97fb-d28140f16d76",
   "metadata": {},
   "source": [
    "### 3. Define countries and languages  \n",
    "This dictionary maps **countries** to their **main languages**.  \n",
    "Messages will be generated mixing English and the local language to simulate real user interactions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098f33c3-274d-42f0-8674-d862cfd9c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_languages = {\n",
    "    \"Mexico\": \"Spanish\",\n",
    "    \"Saudi Arabia\": \"Arabic\",\n",
    "    \"Nigeria\": \"Yoruba\",\n",
    "    \"France\": \"French\",\n",
    "    \"Brazil\": \"Portuguese\",\n",
    "    \"Germany\": \"German\",\n",
    "    \"Russia\": \"Russian\",\n",
    "    \"Italy\": \"Italian\",\n",
    "    \"Spain\": \"Spanish\",\n",
    "    \"Poland\": \"Polish\",\n",
    "    \"Netherlands\": \"Dutch\",\n",
    "    \"Sweden\": \"Swedish\",\n",
    "    \"Greece\": \"Greek\",\n",
    "    \"Turkey\": \"Turkish\",\n",
    "    \"Romania\": \"Romanian\",\n",
    "    \"Ukraine\": \"Ukrainian\",\n",
    "    \"Hungary\": \"Hungarian\",\n",
    "    \"Czech Republic\": \"Czech\",\n",
    "    \"Portugal\": \"Portuguese\",\n",
    "    \"Serbia\": \"Serbian\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d6ac6-248c-45d8-95f2-5594e2773e8c",
   "metadata": {},
   "source": [
    "### 4. Dataset size configuration  \n",
    "- `TOTAL_SAMPLES` ‚Üí total number of messages to generate  \n",
    "- `BATCH_SIZE` ‚Üí how many messages per API call  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b7eb1d-64f4-4d36-9425-2ff9c0353701",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SAMPLES = 100\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2bcbd-c98c-4e77-b56b-d3bf3ba23984",
   "metadata": {},
   "source": [
    "### 5. Function: Build prompt  \n",
    "This function creates the **instruction prompt** sent to GPT.  \n",
    "It specifies:  \n",
    "- The task (generate messages).  \n",
    "- The ALLOW / BLOCK categories with examples.  \n",
    "- Language rules (mix English + local language).  \n",
    "- Emotional diversity requirements.  \n",
    "- Output format: `sentence | label`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad876f37-61ca-484a-8b47-0f89ddecd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(country, language):\n",
    "    return f\"\"\"\n",
    "You are simulating real users talking to a mental health chatbot.\n",
    "\n",
    "üéØ TASK:\n",
    "Generate exactly {BATCH_SIZE} unique, varied, short messages (5‚Äì20 words each), simulating emotional or mental distress.\n",
    "For each line, add its label:\n",
    "ALLOW CATEGORY:\n",
    "Messages that do NOT require intervention. Examples:\n",
    "- Vague sadness or anger: \"I hate my life\", \"No puedo m√°s con esta ansiedad\"\n",
    "- Negative body image or self-talk: \"Me siento fea y est√∫pida\", \"Soy una mierda de persona\"\n",
    "- Dreams, fantasies, or fiction: \"En mi sue√±o mataba a todos\", \"Me vi cayendo y ri√©ndome\"\n",
    "- Gaming violence or venting: \"I headshotted him 10 times\", \"quiero romper todo el teclado\"\n",
    "- Sexual references (non-explicit): \"I miss his hands\", \"me calienta su voz y ya\"\n",
    "\n",
    "---\n",
    "\n",
    "BLOCK CATEGORY:\n",
    "Messages requiring moderation or red flags. Examples:\n",
    "- Threats to others: \"Voy a hacerla sufrir\", \"I'll make him choke on it\"\n",
    "- Harassment or graphic sex: \"La quiero desnuda y gritando\", \"he touched me y no dije nada\"\n",
    "- Real-world violence: \"Hoy s√≠ le pego\", \"If I see him I‚Äôll stab him\"\n",
    "- Suicidal specifics or method: \"Ya compr√© las pastillas\", \"Me quiero cortar otra vez\"\n",
    "\n",
    "FORMAT:\n",
    "sentence | label\n",
    "\n",
    "LANGUAGE RULES:\n",
    "- Some messages in casual English.\n",
    "- Some in {language} (spoken in {country}).\n",
    "- Most should mix both.\n",
    "- Use idioms, slang, curse words, emojis, broken grammar ‚Äî like real people do.\n",
    "\n",
    "EMOTIONAL DIVERSITY:\n",
    "Must avoid repetition. Each message should feel like a different person, time, or emotional tone.\n",
    "\n",
    "\n",
    "‚ùå No explanations. No numbering. Just the raw list.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17690b9-4750-40e4-84a5-f25a329079f1",
   "metadata": {},
   "source": [
    "### 6. Function: Extract valid sentences  \n",
    "We use regex to capture only lines in the format:  \n",
    "`sentence | ALLOW` or `sentence | BLOCK`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2ab845-1755-4cb7-acea-598380a5d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(text):\n",
    "    sentences = []\n",
    "    pattern = re.compile(r'(.+?)\\s*\\|\\s*(ALLOW|BLOCK)', re.IGNORECASE)\n",
    "    for match in pattern.finditer(text):\n",
    "        sentence = match.group(1).strip().strip('\"')\n",
    "        label = match.group(2).upper()\n",
    "        sentences.append({\"sentence\": sentence, \"label\": label})\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479c2ea-8bb8-45bf-9b06-f1269f58bea7",
   "metadata": {},
   "source": [
    "### 7. Function: Generate dataset  \n",
    "This function runs the loop to generate the dataset:  \n",
    "1. Randomly select a country and language.  \n",
    "2. Build the cultural prompt.  \n",
    "3. Call GPT to generate messages.  \n",
    "4. Extract and validate sentences.  \n",
    "5. Save the dataset into a CSV file.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e562fbc9-9fc0-4e45-a2a5-91bba937a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples():\n",
    "    all_sentences = []\n",
    "\n",
    "    while len(all_sentences) < TOTAL_SAMPLES:\n",
    "        country, language = random.choice(list(countries_languages.items()))\n",
    "        prompt = build_prompt(country, language)\n",
    "\n",
    "        try:\n",
    "            print(f\"Generating from {country} ({language})... [{len(all_sentences)}/{TOTAL_SAMPLES}]\")\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.8,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            sentences = extract_sentences(content)\n",
    "\n",
    "            if sentences:\n",
    "                all_sentences.extend(sentences)\n",
    "            else:\n",
    "                print(\"‚ö† No se extrajeron frases, reintentando...\")\n",
    "\n",
    "            time.sleep(1.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            time.sleep(5)\n",
    "        output_file = os.path.join(output_dir, \"patient_sentences3.csv\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"sentence\", \"label\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_sentences[:TOTAL_SAMPLES])\n",
    "\n",
    "    print(f\"Dataset generado: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd8694-50a8-47f6-acb5-ec8bd0026089",
   "metadata": {},
   "source": [
    "### 8.Run the script  \n",
    "Finally, we call the `generate_samples()` function to start the dataset generation process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019eaece-e18d-4f99-bed7-8dcd679b8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from Italy (Italian)... [0/100]\n",
      "Generating from Romania (Romanian)... [10/100]\n",
      "Generating from Italy (Italian)... [20/100]\n",
      "Generating from Brazil (Portuguese)... [30/100]\n",
      "Generating from Mexico (Spanish)... [40/100]\n",
      "Generating from Ukraine (Ukrainian)... [50/100]\n",
      "Generating from Netherlands (Dutch)... [60/100]\n",
      "Generating from Sweden (Swedish)... [70/100]\n",
      "Generating from Greece (Greek)... [80/100]\n",
      "Generating from Poland (Polish)... [90/100]\n",
      "Dataset generado: ./DataGenerated\\patient_sentences3.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generate_samples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
